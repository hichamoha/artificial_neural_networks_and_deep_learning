{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Counting corners in polygons\n",
    "\n",
    "In this optional exercise you will: \n",
    "\n",
    "* Train a CNN to count corners in polygons\n",
    "\n",
    "## The data\n",
    "\n",
    "The images are almost black and white images of polygons, from triangles up to polygons with 10 corners.\n",
    "The task is simply to be able to predict the number of corners given an input image. The size of the \n",
    "images are 100x100. There is a training dataset of 5000 images and a testset of also 5000 images. There is also\n",
    "a dataset where training data only contain odd number of corners and testdata only even number of corners.\n",
    "\n",
    "## The exercises\n",
    "See cell # below.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CellName: Init (#1)\n",
    "### CellType: Needed\n",
    "### Cell instruction: Initializing the libraries\n",
    "In the cell below, we import all the libraries that are needed for this exercises. There is one configuration parameter that you can change in this cell\n",
    "\n",
    "* Inline or \"pop out\" plots.\n",
    "\n",
    "See comments in the cell for more information. Run the cell by entering into the cell and press \"CTRL Enter\".\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"\"\n",
    "\n",
    "import keras\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Input, Activation\n",
    "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.layers import Lambda, concatenate\n",
    "from keras.layers import LSTM, GRU, SimpleRNN, RNN\n",
    "\n",
    "from keras.optimizers import SGD, Adam, RMSprop, Nadam\n",
    "from keras import backend as K\n",
    "\n",
    "from sklearn.metrics import *\n",
    "\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())\n",
    "\n",
    "# To have the plots inside the notebook \"inlin\" should be True. \n",
    "# If \"inlin\" = False, then plots will pop out of the notebook\n",
    "inlin = True # True/False\n",
    "if inlin:\n",
    "    %matplotlib inline\n",
    "else:\n",
    "    %matplotlib\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CellName: Data (#2)\n",
    "### CellType: Needed\n",
    "### Cell instruction: Function for loading the polygons\n",
    "\n",
    "Run the cell by entering into the cell and press \"CTRL Enter\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadImages(folder,trgFile,n):\n",
    "    from scipy import misc\n",
    "    def load_pics(folder,n):\n",
    "        imgs = []\n",
    "        for i in range(n):\n",
    "            img = misc.imread(folder+\"img_{:05}.png\".format(i+1))\n",
    "            ch = img[:,:,0]\n",
    "            imgs.append(ch)\n",
    "        return np.array(imgs)\n",
    "\n",
    "    def load_labels(fn):\n",
    "        return np.loadtxt(fn, usecols=0)\n",
    "\n",
    "    pic = load_pics(folder+\"/\", n)\n",
    "    ndata, width, height = pic.shape\n",
    "\n",
    "    inp = (pic/np.float32(255)).reshape(n, width, height, 1)\n",
    "    trg = load_labels(trgFile)\n",
    "    trg = trg[0:n]\n",
    "\n",
    "    return inp, trg, width, height\n",
    "\n",
    "def loadDataAll(nTrn, nTst):\n",
    "    # Load data\n",
    "    (trnInp, trnTrg, imgW, imgH) = loadImages(\"polyAll-trn\", \"polyAll-trn_trg.csv\", nTrn)\n",
    "    (tstInp, tstTrg, imgW, imgH) = loadImages(\"polyAll-tst\", \"polyAll-tst_trg.csv\", nTst)\n",
    "\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        trnInp = trnInp.reshape(trnInp.shape[0], 1, imgH, imgW)\n",
    "        tstInp = tstInp.reshape(tstInp.shape[0], 1, imgH, imgW)\n",
    "        input_shape = (1, imgH, imgW)\n",
    "    else:\n",
    "        trnInp = trnInp.reshape(trnInp.shape[0], imgH, imgW, 1)\n",
    "        tstInp = tstInp.reshape(tstInp.shape[0], imgH, imgW, 1)\n",
    "        input_shape = (imgH, imgW, 1)\n",
    "\n",
    "    print('trnInp shape:', trnInp.shape)\n",
    "    print('tstInp shape:', tstInp.shape)\n",
    "\n",
    "    return trnInp, trnTrg, tstInp, tstTrg, input_shape\n",
    "\n",
    "def loadDataOddEven(nTrn, nTst):\n",
    "    # Load data\n",
    "    (trnInp, trnTrg, imgW, imgH) = loadImages(\"polyOdd-trn\", \"polyOdd-trn_trg.csv\", nTrn)\n",
    "    (tstInp, tstTrg, imgW, imgH) = loadImages(\"polyEven-tst\", \"polyEven-tst_trg.csv\", nTst)\n",
    "\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        trnInp = trnInp.reshape(trnInp.shape[0], 1, imgH, imgW)\n",
    "        tstInp = tstInp.reshape(tstInp.shape[0], 1, imgH, imgW)\n",
    "        input_shape = (1, imgH, imgW)\n",
    "    else:\n",
    "        trnInp = trnInp.reshape(trnInp.shape[0], imgH, imgW, 1)\n",
    "        tstInp = tstInp.reshape(tstInp.shape[0], imgH, imgW, 1)\n",
    "        input_shape = (imgH, imgW, 1)\n",
    "\n",
    "    print('trnInp shape:', trnInp.shape)\n",
    "    print('tstInp shape:', tstInp.shape)\n",
    "\n",
    "    return trnInp, trnTrg, tstInp, tstTrg, input_shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CellName: PlotImg (#3)\n",
    "### CellType: Information\n",
    "### Cell instruction: Show some of the images\n",
    "\n",
    "Here we look at the first ten pictures in the training set, and their respective targets. \n",
    "\n",
    "Run the cell by entering into the cell and press \"CTRL Enter\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trnInp, trnTrg, tstInp, tstTrg, input_shape = loadDataAll(10,10)\n",
    "#trnInp, trnTrg, tstInp, tstTrg, input_shape = loadDataOddEven(10,10)\n",
    "\n",
    "plt.figure(1, figsize=(15,10))\n",
    "plt.imshow(trnInp[:10,:,:].swapaxes(0,1).reshape(input_shape[1],10*input_shape[1]),cmap=\"gray\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "\n",
    "print(\"Targets:\")\n",
    "print(trnTrg[:10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CellName: Stats (#4)\n",
    "### CellType: Needed\n",
    "### Cell instruction: Plot a confusion matrix\n",
    "\n",
    "Run the cell by entering into the cell and press \"CTRL Enter\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm,\n",
    "                          target_names,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=None,\n",
    "                          normalize=True):\n",
    "    \"\"\"\n",
    "    given a sklearn confusion matrix (cm), make a nice plot\n",
    "\n",
    "    Arguments\n",
    "    ---------\n",
    "    cm:           confusion matrix from sklearn.metrics.confusion_matrix\n",
    "\n",
    "    target_names: given classification classes such as [0, 1, 2]\n",
    "                  the class names, for example: ['high', 'medium', 'low']\n",
    "\n",
    "    title:        the text to display at the top of the matrix\n",
    "\n",
    "    cmap:         the gradient of the values displayed from matplotlib.pyplot.cm\n",
    "                  see http://matplotlib.org/examples/color/colormaps_reference.html\n",
    "                  plt.get_cmap('jet') or plt.cm.Blues\n",
    "\n",
    "    normalize:    If False, plot the raw numbers\n",
    "                  If True, plot the proportions\n",
    "\n",
    "    Usage\n",
    "    -----\n",
    "    plot_confusion_matrix(cm           = cm,                  # confusion matrix created by\n",
    "                                                              # sklearn.metrics.confusion_matrix\n",
    "                          normalize    = True,                # show proportions\n",
    "                          target_names = y_labels_vals,       # list of names of the classes\n",
    "                          title        = best_estimator_name) # title of graph\n",
    "\n",
    "    Citiation\n",
    "    ---------\n",
    "    http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n",
    "\n",
    "    \"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "    import itertools\n",
    "\n",
    "    accuracy = np.trace(cm) / float(np.sum(cm))\n",
    "    misclass = 1 - accuracy\n",
    "\n",
    "    if cmap is None:\n",
    "        cmap = plt.get_cmap('Blues')\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "\n",
    "    if target_names is not None:\n",
    "        tick_marks = np.arange(len(target_names))\n",
    "        plt.xticks(tick_marks, target_names, rotation=45)\n",
    "        plt.yticks(tick_marks, target_names)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "\n",
    "    thresh = cm.max() / 1.5 if normalize else cm.max() / 2\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        if normalize:\n",
    "            plt.text(j, i, \"{:0.4f}\".format(cm[i, j]),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "        else:\n",
    "            plt.text(j, i, \"{:,}\".format(cm[i, j]),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label\\naccuracy={:0.4f}; misclass={:0.4f}'.format(accuracy, misclass))\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CellName: Ex1 (#5)\n",
    "### CellType: Exercise\n",
    "### Cell instruction: Instructions for question 1-2\n",
    "\n",
    "## CNN for counting corners\n",
    "\n",
    "#### Question 1\n",
    "The question is simple! **Find a CNN model that can accurately counts the corners in the test data set.**\n",
    "You have access to 5000 training images, but you may have to reduce that to be able to run it on your computer. In the\n",
    "example code below I use 1000 training images.\n",
    "\n",
    "**Hint 1** The cell below contains my simple model that is not so accurate. You can use the code as a starting point.\n",
    "**Hint 2** How can we count corners? My suggestion is to solve this using a regression approach. The CNN will try\n",
    "to predict the number of corners. So my output is a single linear node and I use MSE as a loss function. You can of\n",
    "course also try to solve it using a classification approach, but then you will a problem, extrapolating to other\n",
    "number of corners.\n",
    "**Hint 3** The target data for the images are the number of corners. I rescale this by 10 before training.\n",
    "**Hint 4** Cells #6 and #7 contains some code for visualizing the results of your model.\n",
    "\n",
    "#### Question 2\n",
    "There is a function \"loadDataOddEven\" that loads a training dataset with only odd number of corners and a test\n",
    "dataset with only even number of corners. **Try to \"solve\" this problem with a CNN!**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "num_output = 1\n",
    "epochs = 10\n",
    "\n",
    "# Get the training data\n",
    "(trnInp, trnTrg, tstInp, tstTrg, input_shape) = loadDataAll(1000,5000)\n",
    "trnTrg /= 10;\n",
    "tstTrg /= 10;\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# Filter layer\n",
    "model.add(Conv2D(10, (5,5), strides=2, padding='same', activation='relu', input_shape=input_shape))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))   \n",
    "\n",
    "# Filter layer\n",
    "model.add(Conv2D(10, (3,3), strides=1, padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))   \n",
    "\n",
    "# The dense layers\n",
    "model.add(Flatten())\n",
    "model.add(Dense(10, activation='relu'))\n",
    "#model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(num_output, activation='linear'))\n",
    "    \n",
    "model.compile(loss='mean_squared_error',\n",
    "              optimizer=Adam(lr=0.001),\n",
    "              metrics=['mse'])\n",
    "model.summary()\n",
    "\n",
    "estimator = model.fit(trnInp, trnTrg,\n",
    "            batch_size=batch_size,\n",
    "            epochs=epochs,\n",
    "            verbose=1,\n",
    "            validation_data=(tstInp, tstTrg))\n",
    "\n",
    "trnSc = model.evaluate(trnInp, trnTrg, verbose=0)\n",
    "tstSc = model.evaluate(tstInp, tstTrg, verbose=0)\n",
    "print('Trn loss:', trnSc[0])\n",
    "print('Tst loss:', tstSc[0])\n",
    "\n",
    "# Plot the learning curves\n",
    "plt.figure()\n",
    "plt.plot(estimator.history['loss'], label='Training')\n",
    "plt.plot(estimator.history['val_loss'], label='Validation')\n",
    "plt.ylabel('MSE')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CellName: Scatterplot (#6)\n",
    "### CellType: Exercise\n",
    "### Cell instruction: Make a scatter plot\n",
    "\n",
    "This cell just makes two scatter plots between the predicted output and the target output, for both\n",
    "training and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plots of predicted and true values\n",
    "trnPred = model.predict(trnInp)*10\n",
    "tstPred = model.predict(tstInp)*10\n",
    "trnTr = trnTrg*10\n",
    "tstTr = tstTrg*10\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(trnPred[:], trnTr[:], 'g.', label='Predict vs True (Training)')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(tstPred[:], tstTr[:], 'g.', label='Predict vs True (Test)')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CellName: Confusion (#7)\n",
    "### CellType: Exercise\n",
    "### Cell instruction: Plot confusion matrix\n",
    "\n",
    "This cell just plots the confusion matrices for both training and testdata. In order to make a \"prediction\" of the number of corners, the output from the CNN model is rounded to nearest integer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Scatter plots of predicted and true values\n",
    "trnPred = model.predict(trnInp)*10\n",
    "tstPred = model.predict(tstInp)*10\n",
    "trnTr = trnTrg*10\n",
    "tstTr = tstTrg*10\n",
    "\n",
    "nTrn = trnInp.shape[0]\n",
    "nTst = tstInp.shape[0]\n",
    "\n",
    "trnClPred = np.rint(trnPred).reshape(nTrn)\n",
    "trnClPred = trnClPred.astype(int)\n",
    "trnClTrg = np.rint(trnTr).astype(int)\n",
    "\n",
    "tstClPred = np.rint(tstPred).reshape(nTst)\n",
    "tstClPred = tstClPred.astype(int)\n",
    "tstClTrg = np.rint(tstTr).astype(int)\n",
    "\n",
    "minTrn = min(min(trnClTrg), min(trnClPred))\n",
    "maxTrn = max(max(trnClTrg), max(trnClPred))\n",
    "trgName = [];\n",
    "for x in range(minTrn, maxTrn+1):\n",
    "    trgName.append(str(x))\n",
    "\n",
    "minTst = min(min(tstClTrg), min(tstClPred))\n",
    "maxTst = max(max(tstClTrg), max(tstClPred))\n",
    "tstName = [];\n",
    "for x in range(minTst, maxTst+1):\n",
    "    tstName.append(str(x))\n",
    "    \n",
    "confuTrn = confusion_matrix(trnClTrg, trnClPred)\n",
    "confuTst = confusion_matrix(tstClTrg, tstClPred)\n",
    "\n",
    "plot_confusion_matrix(cm           = confuTrn, \n",
    "                      normalize    = False,\n",
    "                      target_names = trgName,\n",
    "                      title        = \"Confusion Matrix: Training\")\n",
    "\n",
    "plot_confusion_matrix(cm           = confuTst, \n",
    "                      normalize    = False,\n",
    "                      target_names = tstName,\n",
    "                      title        = \"Confusion Matrix: Test\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
